{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Linear Regime Pytorch sigmoid.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcoxLuiYhxrb"
      },
      "source": [
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib \n",
        "matplotlib.use('pdf')\n",
        "from mpl_toolkits import mplot3d\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-white')\n",
        "\n",
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJwdemW7JO3I"
      },
      "source": [
        "# Histogram eigenvalues of each X'X\n",
        "def histeig(eigs, ax, xgrid=None, dgrid=None, bins=100, xlim=None, ylim=None, title=None):\n",
        "    if xlim is not None:\n",
        "        eigs = eigs[np.nonzero(eigs <= xlim[1])[0]]\n",
        "        h = ax.hist(eigs, bins=np.linspace(xlim[0], xlim[1], num=bins))\n",
        "    else:\n",
        "        h = ax.hist(eigs, bins=bins)\n",
        "    if xgrid is not None:\n",
        "        space = h[1][1] - h[1][0]\n",
        "        ax.plot(xgrid, dgrid * len(eigs) * space, 'r', label='Prediction at initial', linewidth=2)\n",
        "        ax.legend()\n",
        "    ax.set_title(title, fontsize=12)\n",
        "    ax.set_xlim(xlim)\n",
        "    if ylim is None:\n",
        "        ax.set_ylim([0, max(h[0]) * 1.5])\n",
        "    else:\n",
        "        ax.set_ylim(ylim)\n",
        "    return ax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLMsXvmDiRme"
      },
      "source": [
        "**Activation Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHf2lvVniLkf"
      },
      "source": [
        "def lin(X):\n",
        "  return X\n",
        "# relu\n",
        "# b0 = 1/4\n",
        "# b1 = 1/4\n",
        "def relu(X,normalize=True):\n",
        "    X[X<0] = 0\n",
        "    if normalize:\n",
        "        return np.sqrt(2*np.pi/(np.pi-1))*(X-1/np.sqrt(2*np.pi))\n",
        "    else:\n",
        "        return X\n",
        "\n",
        "def relu_grad(X,normalize=True):\n",
        "    X[X<0] = 0\n",
        "    X[X>0] = 1\n",
        "    if normalize:\n",
        "        X[X>0] = np.sqrt(2*np.pi/(np.pi-1))\n",
        "    return X\n",
        "\n",
        "# softplus\n",
        "# b0 = 1/4\n",
        "# b1 = 0.043379\n",
        "SP = torch.nn.Softplus()\n",
        "def softplus(X,normalize=True):\n",
        "    if normalize:\n",
        "        c0 = 0.806059\n",
        "        c1 = 0.271514\n",
        "        return (SP(X)-c0) / (c1)**0.5\n",
        "    else:\n",
        "        return SP(X)\n",
        "\n",
        "def softplus_grad(X,normalize=True):\n",
        "    if normalize:\n",
        "        c1 = 0.271514\n",
        "        return torch.sigmoid(X) / (c1)**0.5\n",
        "    else:\n",
        "        return torch.sigmoid(X)\n",
        "\n",
        "# sigmoid\n",
        "# b0=0.042692\n",
        "# b1 =0.002144 \n",
        "def sigmoid(X,normalize=True):\n",
        "    X = torch.sigmoid(X)\n",
        "    if normalize:\n",
        "        c = np.sqrt(0.21747 / (2 * np.sqrt(2 * np.pi)))\n",
        "        return (X-0.5)/c\n",
        "    else:\n",
        "        return X\n",
        "\n",
        "def sigmoid_grad(X,normalize=True):\n",
        "    X = torch.sigmoid(X)\n",
        "    if normalize:\n",
        "        c = np.sqrt(0.21747 / (2 * np.sqrt(2 * np.pi)))\n",
        "        return X * (1-X) / c\n",
        "    else:\n",
        "        return X * (1-X)\n",
        "\n",
        "def tanh(X,normalize=False):\n",
        "    X = torch.tanh(X)\n",
        "    if normalize:\n",
        "        c = 0.627928\n",
        "        return X / c\n",
        "    else:\n",
        "        c = 5\n",
        "        return X * c\n",
        "\n",
        "def tanh_grad(X,normalize=False):\n",
        "    X = torch.tanh(X)\n",
        "    if normalize:\n",
        "        c = 0.627928\n",
        "        return (1 - X**2) / c\n",
        "    else:\n",
        "        c = 5\n",
        "        return (1 - X**2) * c\n",
        "\n",
        "def quadratic(X,normalize=True):\n",
        "    if normalize:\n",
        "        return (X**2-1) / np.sqrt(2)\n",
        "    else:\n",
        "        return X**2 / 2\n",
        "\n",
        "def quadratic_grad(X,normalize=True):\n",
        "    if normalize:\n",
        "        return np.sqrt(2)*X\n",
        "    else:\n",
        "        return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5110edzYgxG"
      },
      "source": [
        "# Student Model\n",
        "\n",
        "**Two-layer Neural Network:** \n",
        "\n",
        "$f(\\mathbf{x}) = \\sum_{i=1}^h a_i\\phi(\\langle \\mathbf{x},\\mathbf{w}_i\\rangle)$. $\\mathbf{w}_i\\in\\mathbb{R}^d$. \n",
        "\n",
        "\\\\\n",
        "**Initialization:** \n",
        "\n",
        "- $w_{ij} \\sim \\mathcal{N}(0,d^{-2\\alpha_1})$.\n",
        "\n",
        "- $a_i \\sim \\mathcal{N}(0,h^{-2\\alpha_2})$. \n",
        "\n",
        "**Note:** \n",
        "\n",
        "- $\\alpha_2=1  \\Rightarrow$  mean-field regime.\n",
        "- $\\alpha_1=\\alpha_2=1/2  \\Rightarrow$  kernel regime.\n",
        "\n",
        "**Current Setting:** $\\alpha_1 = 1/2, \\alpha_2 = 1/2$. \n",
        "\n",
        "\\\\\n",
        "\n",
        "# Proportional limit\n",
        "\n",
        "- Let $n$ be the number of training sample size.\n",
        "-  $\\gamma_1:=\\lim d/n\\in (0,\\infty)$ as $n\\to \\infty$.\n",
        "- $\\gamma_2:=\\lim h/n\\in (0,\\infty)$ as $n\\to \\infty$.\n",
        "\n",
        "\\\\\n",
        "\n",
        "# Gradient Update\n",
        "\n",
        "- $a_{t+1} = a_t - \\eta\\nabla_a L(f)$.\n",
        "- $w_{t+1} = w_t - \\eta\\nabla_w L(f)$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCThV4dcYZOw"
      },
      "source": [
        "# activation function\n",
        "act = sigmoid\n",
        "grad = sigmoid_grad\n",
        "\n",
        "# parameterization\n",
        "mean_field = False\n",
        "\n",
        "# scaling of parameters\n",
        "alpha1 = 0.5\n",
        "alpha2 = 0.5\n",
        "\n",
        "train_2nd = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7domH4BZYrWn"
      },
      "source": [
        "**Initialization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DAgr7gWiWau"
      },
      "source": [
        "# Data Distribution\n",
        "**Single-index Target Function on Unit Gaussian Input**. \n",
        "\n",
        "+ $\\mathbf{x}\\sim\\mathcal{N}(0,\\mathbf{I}_d)$.\n",
        "+ $y = \\phi(\\langle\\mathbf{x},\\mathbf{\\theta}_*\\rangle)$. $\\mathbf{\\theta}_*$ can exhibit certain sparse structure \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxujtC2xiU82"
      },
      "source": [
        "def unit_Gaussian(n,d):\n",
        "    return torch.FloatTensor(n,d).normal_(mean=0,std=1).to(device)  \n",
        "\n",
        "def single_index(n,d,n1,sigma=0.1,nonlin=relu):\n",
        "    X = unit_Gaussian(n,d)\n",
        "    X_test = unit_Gaussian(n1,d)\n",
        "    theta = torch.FloatTensor(d,1).normal_(mean=0,std=1).to(device)  \n",
        "    theta = theta / torch.norm(theta)\n",
        "    if sigma == 0:\n",
        "        return X, nonlin(X@theta), X_test, nonlin(X_test@theta)\n",
        "    else:\n",
        "        return X, nonlin(X@theta) + torch.FloatTensor(n,1).normal_(mean=0,std=sigma).to(device), X_test, nonlin(X_test@theta)\n",
        "\n",
        "def multi_index(n,d,n1,sigma=0.1,ind=1,nonlin=relu):\n",
        "    X = unit_Gaussian(n,d)\n",
        "    X_test = unit_Gaussian(n1,d)\n",
        "    theta = torch.FloatTensor(d,ind).normal_(mean=0,std=1).to(device) \n",
        "    theta = theta / torch.norm(theta)\n",
        "    a = torch.ones([ind,1]).to(device) / (ind**0.5)\n",
        "    Y = nonlin(X@theta)@a\n",
        "    Y_test = nonlin(X_test@theta)@a\n",
        "    if sigma == 0:\n",
        "        return X, Y, X_test, Y_test\n",
        "    else:\n",
        "        return X, Y + torch.FloatTensor(n,1).normal_(mean=0,std=sigma).to(device), X_test, Y_test\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNJfIdSm_F08"
      },
      "source": [
        "**Training Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLbcqnX2_EWN",
        "outputId": "1eb6fc50-153f-4dd6-9dd0-1bb73709256b"
      },
      "source": [
        "SNR = 12\n",
        "# std of Gaussian\n",
        "sigma = (1/SNR)**0.5\n",
        "# sparsity of target function\n",
        "spar = 1\n",
        "\n",
        "print(\"SNR: %f\" % (SNR))\n",
        "print(\"noise: %f\" % (sigma))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SNR: 12.000000\n",
            "noise: 0.288675\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffXy_3l02A23"
      },
      "source": [
        "# Training Procedure\n",
        "\n",
        "**Squared Loss:** \n",
        "$L(f) = \\frac{1}{n}\\sum_{i=1}^n (y_i - f(\\mathbf{x}_i))^2$.\n",
        "\n",
        "OR\n",
        "\n",
        "**Logistic Loss:** \n",
        "$L(f) = \\frac{1}{n}\\sum_{i=1}^n \\text{log}(1 + \\text{exp}(-y_i\\cdot f(\\mathbf{x}_i)))$.\n",
        "\n",
        "\\\\\n",
        "\n",
        "**$\\ell_2$ Regularization:**  \n",
        "$R(f) = \\lambda(\\|\\mathbf{W}\\|^2_F + \\|\\mathbf{a}\\|_2^2)$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65ug5tDsoZQy"
      },
      "source": [
        "# Y1 - true labels\n",
        "# Y2 - model prediction\n",
        "\n",
        "def mse(Y1,Y2):\n",
        "    return torch.mean((Y1-Y2)**2)\n",
        "\n",
        "def logistic(Y1,Y2):\n",
        "    return torch.mean(SP(-Y1*Y2))\n",
        "\n",
        "def mse_grad(Y1,Y2):\n",
        "    return Y1 - Y2\n",
        "\n",
        "def logistic_grad(Y1,Y2):\n",
        "    return Y1 * torch.sigmoid(-Y1 * Y2)\n",
        "\n",
        "\n",
        "# ------------------------------------\n",
        "# Choose objective\n",
        "\n",
        "loss_fn = mse\n",
        "loss_grad = mse_grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krNoZ775VMhg"
      },
      "source": [
        "**Training Neural Networks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xKFSzm4LHiZg",
        "outputId": "330be520-940b-4021-f1ad-a3b7a2c2d297"
      },
      "source": [
        "gamma1 = 0.1 # gamma1 = d/n\n",
        "gamma2 = 0.5 # gamma2 = h/n\n",
        "\n",
        "# L2 regularization\n",
        "lda = 0\n",
        "# Learning rate\n",
        "eta = 0.2\n",
        "# Max step size\n",
        "n_max = 6100\n",
        "n_min = 1000\n",
        "# Number of steps\n",
        "steps = 1000\n",
        "\n",
        "# --------------------------------------------\n",
        "runs = 5\n",
        "inc= 300\n",
        "n_list = np.arange(n_min,n_max,inc)\n",
        "\n",
        "NN_loss = np.zeros([len(n_list),runs,2])\n",
        "NN_weight_diff = np.zeros([len(n_list),runs,7])\n",
        "\n",
        "for i in tqdm(range(len(n_list))):\n",
        "    n = n_list[i]\n",
        "    print(n)\n",
        "    d = int(n*gamma1)\n",
        "    h = int(n*gamma2)\n",
        "    # training and test data with noise\n",
        "    X,Y,X_test,Y_test = multi_index(n,d,int(2*n/3),sigma=sigma,ind=1,nonlin=lin)\n",
        "    for j in tqdm(range(runs)):\n",
        "          W = torch.FloatTensor(d,h).normal_(mean=0,std=(1/d)**alpha1).to(device)\n",
        "          b = torch.FloatTensor(h,1).normal_(mean=0,std=(1/h)**alpha2).to(device)\n",
        "          _,s0,_ = torch.svd(torch.t(W)@W)\n",
        "          Ws = W.clone()\n",
        "          bs = b.clone()\n",
        "          XX = X@torch.t(X) / d\n",
        "          CK0 = act(X@W)@torch.t(act(X@W)) / h\n",
        "          eta_w = eta\n",
        "          eta_b = eta\n",
        "          XW_grad0 = grad(X@W)\n",
        "          S0 = XW_grad0*((torch.ones(n, 1).to(device))@torch.t(b))\n",
        "          RF0 = S0@torch.t(S0)\n",
        "          NTK0 = XX * RF0\n",
        "          if train_2nd:\n",
        "              NTK0 = NTK0 + CK0\n",
        "          for k in range(steps):\n",
        "              ys = act(X@Ws)@bs\n",
        "              # update parameters\n",
        "              dW = torch.t(X) @ (loss_grad(Y, ys) @ torch.t(bs) * grad(X@Ws)) / n\n",
        "              Ws = Ws + eta_w * (dW - lda*Ws)\n",
        "\n",
        "              if train_2nd:\n",
        "                  db = torch.t(X@Ws)@loss_grad(Y, ys) / n\n",
        "                  bs = bs + eta_b * (db - lda*bs)\n",
        "          XW = act(X@Ws)\n",
        "          y_NN = act(X_test@Ws)@bs\n",
        "          NN_loss[i,j,0] = loss_fn(ys,Y)\n",
        "          NN_loss[i,j,1] = loss_fn(y_NN,Y_test)\n",
        "          _,s1,_ = torch.svd(torch.t(Ws)@Ws)\n",
        "          NN_weight_diff[i,j,0] = torch.abs(s1[0]-s0[0])\n",
        "          NN_weight_diff[i,j,1] = torch.linalg.norm(Ws-W, ord=2)\n",
        "          NN_weight_diff[i,j,2] = torch.linalg.norm(Ws-W, ord='fro')\n",
        "          # CK model\n",
        "          CK1 = act(X@Ws)@torch.t(act(X@Ws)) / h\n",
        "          NN_weight_diff[i,j,3] = torch.linalg.norm(CK1-CK0, ord=2)\n",
        "          NN_weight_diff[i,j,4] = torch.linalg.norm(CK1-CK0, ord='fro')\n",
        "          # NTK model\n",
        "          XW_grad = grad(X@Ws)\n",
        "          S = XW_grad*((torch.ones(n, 1).to(device))@torch.t(bs))\n",
        "          RF = S@torch.t(S)\n",
        "          NTKs = XX * RF\n",
        "          if train_2nd:\n",
        "              NTKs = NTKs + CK1\n",
        "          NN_weight_diff[i,j,5] = torch.linalg.norm(NTKs-NTK0, ord=2)\n",
        "          NN_weight_diff[i,j,6] = torch.linalg.norm(NTKs-NTK0, ord='fro')\n",
        "          print(\"-------------------------------------------------\")\n",
        "          print(\"dimesion: %d; Training Loss: %f\" % (n,loss_fn(ys,Y)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/17 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:00<00:03,  1.20it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 1000; Training Loss: 0.036008\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 40%|████      | 2/5 [00:01<00:02,  1.28it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 1000; Training Loss: 0.037213\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 60%|██████    | 3/5 [00:02<00:01,  1.31it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 1000; Training Loss: 0.035270\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 80%|████████  | 4/5 [00:03<00:00,  1.30it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 1000; Training Loss: 0.034497\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 5/5 [00:03<00:00,  1.30it/s]\n",
            "  6%|▌         | 1/17 [00:03<01:01,  3.85s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 1000; Training Loss: 0.036723\n",
            "1300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:01<00:06,  1.53s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 1300; Training Loss: 0.035472\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 40%|████      | 2/5 [00:03<00:04,  1.53s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 1300; Training Loss: 0.033624\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 60%|██████    | 3/5 [00:04<00:03,  1.52s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 1300; Training Loss: 0.033321\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 80%|████████  | 4/5 [00:06<00:01,  1.52s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 1300; Training Loss: 0.033373\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 5/5 [00:07<00:00,  1.55s/it]\n",
            " 12%|█▏        | 2/17 [00:11<01:32,  6.15s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 1300; Training Loss: 0.033843\n",
            "1600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:02<00:09,  2.32s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 1600; Training Loss: 0.034261\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 40%|████      | 2/5 [00:04<00:06,  2.33s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 1600; Training Loss: 0.034734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 60%|██████    | 3/5 [00:07<00:04,  2.34s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 1600; Training Loss: 0.033672\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 80%|████████  | 4/5 [00:09<00:02,  2.35s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 1600; Training Loss: 0.034027\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 5/5 [00:11<00:00,  2.35s/it]\n",
            " 18%|█▊        | 3/17 [00:23<02:01,  8.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 1600; Training Loss: 0.035779\n",
            "1900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:03<00:15,  3.87s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 1900; Training Loss: 0.033881\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 40%|████      | 2/5 [00:07<00:11,  3.87s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 1900; Training Loss: 0.032673\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 60%|██████    | 3/5 [00:11<00:07,  3.88s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 1900; Training Loss: 0.031737\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 80%|████████  | 4/5 [00:15<00:03,  3.90s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 1900; Training Loss: 0.031449\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 5/5 [00:19<00:00,  3.88s/it]\n",
            " 24%|██▎       | 4/17 [00:42<02:48, 12.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 1900; Training Loss: 0.033652\n",
            "2200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:05<00:22,  5.64s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 2200; Training Loss: 0.031636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 40%|████      | 2/5 [00:11<00:17,  5.68s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 2200; Training Loss: 0.031206\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 60%|██████    | 3/5 [00:17<00:11,  5.73s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 2200; Training Loss: 0.032915\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 80%|████████  | 4/5 [00:22<00:05,  5.72s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 2200; Training Loss: 0.031514\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 5/5 [00:28<00:00,  5.73s/it]\n",
            " 29%|██▉       | 5/17 [01:11<03:43, 18.61s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 2200; Training Loss: 0.033843\n",
            "2500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:08<00:33,  8.37s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "dimesion: 2500; Training Loss: 0.031948\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 1/5 [00:11<00:47, 11.96s/it]\n",
            " 29%|██▉       | 5/17 [01:23<03:20, 16.69s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-6ba13cd9dbed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[0mNN_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m           \u001b[0mNN_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_NN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mWs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m           \u001b[0mNN_weight_diff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ms0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m           \u001b[0mNN_weight_diff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWs\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C831R4-bYZwn"
      },
      "source": [
        "plt.figure(0)\n",
        "FONT_SIZE = 12\n",
        "plt.rc('font',size=FONT_SIZE)\n",
        "fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(18,5))\n",
        "bin = 50\n",
        "\n",
        "ax1.errorbar(n_list, np.mean(NN_loss[:,:,0],axis=1), yerr=np.std(NN_loss[:,:,0],axis=1),elinewidth=3,label='NN_train')\n",
        "ax1.errorbar(n_list, np.mean(NN_loss[:,:,1],axis=1), yerr=np.std(NN_loss[:,:,0],axis=1),elinewidth=3,label='NN_test')\n",
        "#ax1.plot(n_list,NN_loss[:,0],color='g',linewidth=3,label='NN_train')\n",
        "#ax1.plot(n_list,NN_loss[:,1],color='r',linewidth=3,label='NN_test')\n",
        "ax1.set_xlabel('Sample Dimension n')\n",
        "ax1.set_ylabel('Training and Test Losses')\n",
        "ax1.title.set_text('Losses $d/n=$%g'% gamma1)\n",
        "ax1.legend()\n",
        "\n",
        "#histeig(s0.cpu().numpy(), ax2, xgrid=None, dgrid=None, bins=bin, xlim=None, ylim=None, title='initial')\n",
        "#histeig(s.cpu().numpy(), ax2, xgrid=None, dgrid=None, bins=bin, xlim=None, ylim=None, title=None)\n",
        "ax2.hist(s0.cpu().numpy(),histtype='stepfilled', alpha=0.2, bins=bin,label='Initialized')\n",
        "ax2.hist(s1.cpu().numpy(),histtype='stepfilled', alpha=0.2, bins=bin,label='Trained')\n",
        "n_fin = n_max-inc\n",
        "ax2.set_ylim([0,35])\n",
        "ax2.set_xlabel('Eigenvalues of $WW^T$ when n=%d'% n_fin)\n",
        "ax2.legend()\n",
        "\n",
        "ax3.errorbar(n_list, np.mean(NN_weight_diff[:,:,0],axis=1), yerr=np.std(NN_weight_diff[:,:,0],axis=1),elinewidth=3,label='Largest eigenvalue difference')\n",
        "ax3.errorbar(n_list, np.mean(NN_weight_diff[:,:,1],axis=1), yerr=np.std(NN_weight_diff[:,:,1],axis=1),elinewidth=3,label='$\\|W_0-W_f\\|_2$')\n",
        "ax3.errorbar(n_list, np.mean(NN_weight_diff[:,:,2],axis=1), yerr=np.std(NN_weight_diff[:,:,2],axis=1),elinewidth=3,label='$\\|W_0-W_f\\|_{\\text{Frob}}$')\n",
        "#ax3.plot(n_list,NN_weight_diff[:,0],color='g',linewidth=3,label='Largest eigenvalue difference')\n",
        "#ax3.plot(n_list,NN_weight_diff[:,1],color='r',linewidth=3,label='$\\|W_0-W_s\\|_2$')\n",
        "ax3.set_xlabel('Sample Dimension n')\n",
        "ax3.title.set_text('Weight differences, $h/n=$%g'% gamma2)\n",
        "ax3.legend()\n",
        "\n",
        "fig.tight_layout(pad=1.5)\n",
        "fig.savefig('Weight difference gamma1=%g gamma2=%g.png'% (gamma1,gamma2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1aqwUg5Yg99"
      },
      "source": [
        "# spectrum of NTK and CK\n",
        "_,s2,_ = torch.svd(CK0)\n",
        "_,s3,_ = torch.svd(CK1)\n",
        "_,s4,_ = torch.svd(NTK0)\n",
        "_,s5,_ = torch.svd(NTKs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBfvwNRvpnLE"
      },
      "source": [
        "plt.figure(0)\n",
        "FONT_SIZE = 12\n",
        "plt.rc('font',size=FONT_SIZE)\n",
        "fig, (ax1,ax2,ax3,ax4) = plt.subplots(1,4,figsize=(22,5))\n",
        "bin = 50\n",
        "\n",
        "#histeig(s2.cpu().numpy(), ax2, xgrid=None, dgrid=None, bins=bin, xlim=None, ylim=None, title='initial')\n",
        "#histeig(s3.cpu().numpy(), ax2, xgrid=None, dgrid=None, bins=bin, xlim=None, ylim=None, title=None)\n",
        "ax1.hist(s2.cpu().numpy(),histtype='stepfilled', alpha=0.2, bins=bin,label='Initialized')\n",
        "ax1.hist(s3.cpu().numpy(),histtype='stepfilled', alpha=0.2, bins=bin,label='Trained')\n",
        "n_fin = n_max-inc\n",
        "ax1.set_ylim([0,75])\n",
        "ax1.set_xlabel('Eigenvalues of CK when n=%d'% n_fin)\n",
        "ax1.legend()\n",
        "\n",
        "#histeig(s4.cpu().numpy(), ax2, xgrid=None, dgrid=None, bins=bin, xlim=None, ylim=None, title='initial')\n",
        "#histeig(s5.cpu().numpy(), ax2, xgrid=None, dgrid=None, bins=bin, xlim=None, ylim=None, title=None)\n",
        "ax2.hist(s4.cpu().numpy(),histtype='stepfilled', alpha=0.2, bins=bin,label='Initialized')\n",
        "ax2.hist(s5.cpu().numpy(),histtype='stepfilled', alpha=0.2, bins=bin,label='Trained')\n",
        "n_fin = n_max-inc\n",
        "ax2.set_ylim([0,75])\n",
        "ax2.set_xlabel('Eigenvalues of NTK when n=%d'% n_fin)\n",
        "ax2.legend()\n",
        "\n",
        "ax3.errorbar(n_list, np.mean(NN_weight_diff[:,:,3],axis=1), yerr=np.std(NN_weight_diff[:,:,3],axis=1),elinewidth=3,label='$\\|CK_0-CK_s\\|_2$')\n",
        "ax3.errorbar(n_list, np.mean(NN_weight_diff[:,:,4],axis=1), yerr=np.std(NN_weight_diff[:,:,4],axis=1),elinewidth=3,label='$\\|CK_0-CK_s\\|_{\\text{Frob}}$')\n",
        "ax3.set_xlabel('Sample Dimension $n$')\n",
        "ax3.title.set_text('$d/n=$%g, $h/n=$%g'% (gamma1,gamma2))\n",
        "ax3.legend()\n",
        "\n",
        "\n",
        "ax4.errorbar(n_list, np.mean(NN_weight_diff[:,:,5],axis=1), yerr=np.std(NN_weight_diff[:,:,5],axis=1),elinewidth=3,label='$\\|NTK_0-NTK_s\\|_2$')\n",
        "ax4.errorbar(n_list, np.mean(NN_weight_diff[:,:,6],axis=1), yerr=np.std(NN_weight_diff[:,:,6],axis=1),elinewidth=3,label='$\\|NTK_0-NTK_s\\|_{\\text{Frob}}$')\n",
        "ax4.set_xlabel('Sample Dimension $n$')\n",
        "ax4.title.set_text('$d/n=$%g, $h/n=$%g'% (gamma1,gamma2))\n",
        "ax4.legend()\n",
        "\n",
        "fig.tight_layout(pad=1.5)\n",
        "fig.savefig('CK and NTK difference gamma1=%f gamma2=%f.png'% (gamma1,gamma2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChKYXUQl0Ghf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "0f8163ba-9e99-4bda-dadc-71dc181081e1"
      },
      "source": [
        "a = [1,2,3,4,5,6]\n",
        "b = [1,4,9,16,25,36]\n",
        "fig,ax = plt.subplots(1,1)\n",
        "ax.plot(a,b,linewidth=3,label='$\\|CK_0-CK_s\\|_{Frob}$')\n",
        "ax.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f5f97bc7e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdxDFe6RECD_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}